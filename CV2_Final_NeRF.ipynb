{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iTZAmBbKtzY",
        "outputId": "cc0351c0-2331-4d92-9001-15aa2c93729b"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision tensorboard\n",
        "!apt-get install colmap\n",
        "\n",
        "!git clone https://github.com/bmild/nerf.git\n",
        "%cd nerf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXAbZdO6NP_0",
        "outputId": "04158b5b-0097-4528-bfa6-20977f912f56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing nerf_model.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%writefile nerf_model.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NeRF(nn.Module):\n",
        "    def __init__(self, D=8, W=256, input_ch=3, output_ch=4, skips=[4]):\n",
        "        super(NeRF, self).__init__()\n",
        "        self.D = D\n",
        "        self.W = W\n",
        "        self.input_ch = input_ch\n",
        "        self.output_ch = output_ch\n",
        "        self.skips = skips\n",
        "\n",
        "        self.pts_linears = nn.ModuleList(\n",
        "            [nn.Linear(input_ch, W)] + [nn.Linear(W, W) if i not in self.skips else nn.Linear(W + input_ch, W) for i in range(D - 1)])\n",
        "        self.output_linear = nn.Linear(W, output_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = x\n",
        "        for i, l in enumerate(self.pts_linears):\n",
        "            h = F.relu(l(h))\n",
        "            if i in self.skips:\n",
        "                h = torch.cat([x, h], -1)\n",
        "        outputs = self.output_linear(h)\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF81qCGEP75b",
        "outputId": "276d9996-e71d-4e3c-c2c4-aae164335a20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted 220 frames.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "video_path = '/content/video.mp4'\n",
        "output_folder = 'extracted_frames/'\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    cv2.imwrite(f\"{output_folder}/frame_{frame_count:04d}.png\", frame)\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "print(f\"Extracted {frame_count} frames.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvo1rxDKDyIC",
        "outputId": "ea6953e9-0cc3-40d1-eae2-f564139dfbc6"
      },
      "outputs": [],
      "source": [
        "\n",
        "!colmap feature_extractor --database_path /content/database.db --image_path /content/extracted_frames/\n",
        "\n",
        "\n",
        "!colmap exhaustive_matcher --database_path /content/database.db\n",
        "\n",
        "\n",
        "!mkdir /content/sparse\n",
        "!colmap mapper --database_path /content/database.db --image_path /content/extracted_frames/ --output_path /content/sparse\n",
        "\n",
        "\n",
        "!mkdir /content/dense\n",
        "!colmap image_undistorter --image_path /content/extracted_frames/ --input_path /content/sparse/0 --output_path /content/dense --output_type COLMAP\n",
        "!colmap patch_match_stereo --workspace_path /content/dense --workspace_format COLMAP --PatchMatchStereo.geom_consistency true\n",
        "!colmap stereo_fusion --workspace_path /content/dense --workspace_format COLMAP --input_type geometric --output_path /content/dense/fused.ply\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmXrzlpHD1L9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from nerf_model import NeRF\n",
        "\n",
        "num_epochs = 100\n",
        "batch_size = 1024\n",
        "learning_rate = 1e-4\n",
        "log_dir = '/content/logs/'\n",
        "\n",
        "model = NeRF()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "writer = SummaryWriter(log_dir)\n",
        "\n",
        "def data_loader():\n",
        "    while True:\n",
        "        yield torch.randn(batch_size, 3), torch.randn(batch_size, 4)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for step, (rays, targets) in enumerate(data_loader()):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(rays)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        writer.add_scalar('Loss/train', loss.item(), epoch * 100 + step)\n",
        "\n",
        "    print(f\"Epoch {epoch} Loss: {loss.item()}\")\n",
        "\n",
        "torch.save(model.state_dict(), '/content/nerf_model.pth')\n",
        "writer.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWFu3afbD5z0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from nerf_model import NeRF\n",
        "\n",
        "model = NeRF()\n",
        "model.load_state_dict(torch.load('/content/nerf_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "new_views = [torch.randn(3) for _ in range(60)]\n",
        "\n",
        "rendered_images = []\n",
        "for view in new_views:\n",
        "    with torch.no_grad():\n",
        "        img = model(view.unsqueeze(0)).squeeze().numpy()\n",
        "        img = (img - img.min()) / (img.max() - img.min()) * 255\n",
        "        img = img.astype(np.uint8)\n",
        "        rendered_images.append(img)\n",
        "\n",
        "height, width = rendered_images[0].shape[:2]\n",
        "out = cv2.VideoWriter('/content/output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (width, height))\n",
        "for img in rendered_images:\n",
        "    out.write(img)\n",
        "out.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YRuI1csPzKs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
        "from nerf_model import NeRF\n",
        "\n",
        "def load_test_images(path):\n",
        "    images = []\n",
        "    for file in sorted(os.listdir(path)):\n",
        "        img = cv2.imread(os.path.join(path, file))\n",
        "        images.append(img)\n",
        "    return images\n",
        "\n",
        "def load_rendered_images():\n",
        "    return [torch.randn(256, 256, 3).numpy() for _ in range(60)]\n",
        "\n",
        "test_images = load_test_images('/content/test_images/')\n",
        "rendered_images = load_rendered_images()\n",
        "\n",
        "psnr_values = []\n",
        "ssim_values = []\n",
        "for rendered, test in zip(rendered_images, test_images):\n",
        "    psnr_value = psnr(rendered, test)\n",
        "    ssim_value = ssim(rendered, test, multichannel=True)\n",
        "    psnr_values.append(psnr_value)\n",
        "    ssim_values.append(ssim_value)\n",
        "    print(f\"PSNR: {psnr_value}, SSIM: {ssim_value}\")\n",
        "\n",
        "print(f\"Average PSNR: {sum(psnr_values) / len(psnr_values)}, Average SSIM: {sum(ssim_values) / len(ssim_values)}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
